---
title: "TIBs-CDSB-Mapping"
author: "Diana Oaxaca y Mirna Vazquez Rosas Landaa"
date: '2022-07-11'
output: html_document
---

### Mapeo

3. **Profundidad**: La profundidad de cada contig generado se realizó mediante el mapeo de las lecturas al ensamble. Este paso permite evaluar la calidad del ensable y es necesario para hacer la reconstrucción de genomas ya que, como veremos más adelante, es uno de los parámetros que toman en cuenta los bineadores. El mapeo se realizó con la herramienta BBMap del programa **[BBtools](https://jgi.doe.gov/data-and-tools/software-tools/bbtools/)**.

   ```shell
   ## activar el ambiente de bbmap
   conda activate /home/dhernandez/.conda/envs/bbmap
   ## correr bbmap
   bash src/03.depth_assembly.sh
   ## desactivar el ambiente
   conda deactivate
   ```

### Binning

Utilizaremos varios programas para hacer la reconstrucción de los genomas y haremos una comparación de estos.

**NOTA**: Cada programa tiene una ayuda y un manual de usuario, es **importante** revisarlo y conocer cada parámetro que se ejecute. En terminal se puede consultar el manual con el comando `man` y también se puede consultar la ayuda con `-h` o `--help`, por ejemplo `fastqc -h`.

La presente práctica sólo es una representación del flujo de trabajo, sin embargo, no sustituye los manuales de cada programa y el flujo puede variar dependiendo del tipo de datos y pregunta de investigación.

**¡Manos a la obra!**

Conéctate al servidor:

```shell
ssh USER@hpc-matematicas-z.fciencias.unam.mx
```

Crea tu espacio de trabajo y una liga símbólica hacia los datos que se usarán:

# ESTA PARTE ME CAUSA CONFLICTO
```shell
mkdir -p htn/{data,results,logs}
cd htn
ln -s /home/diana/htn/data/* .
cd ..
```

#### MaxBin

#### BinSanity

#### MetaBat

Para MetaBat lo primero que tenemos que hacer es crear un archivo de profundidad utilizando el script **jgi_summarize_bam_contig_depths**.

Entonces primero activamos el ambinte.

```{bash eval=FALSE}
conda activate metabat
```

Como cualquier otro programa **jgi_summarize_bam_contig_depths** tiene opciones, podemos revisarlas. 

```{bash eval=FALSE}
jgi_summarize_bam_contig_depths  --outputDepth htn-depth.txt htn_sorted.bam
```

Okay... exploremos el archivo con **head**

```{bash eval=FALSE}
head htn-depth.txt
```

Para metabat solo necesitamos dos archivos principales:

- El ensamble
- El archivo de profundidad

El resto de argumentos que vamos a usar se refieren a:

 - minCVSum: Cobertura media  total mínima de un contig (suma de profundidad)
 - saveCls: guardar membresías de clúster como un formato de matriz
 - d: salida corta
 - v: salida detallada
 - minCV: Cobertura media mínima de un contig en cada biblioteca para binning.
 - m: Tamaño mínimo de un contig para binning (debe ser >=1500). Usualmente usamos 2000 pero para el ejercicio usaremos 1500
 
```{bash running Metabat, eval=FALSE}
metabat -i htn.fasta -a /home/mirna/03.Mapeo/htn-depth.txt -o bins -t 1 --minCVSum 0 --saveCls -d -v --minCV 0.1 -m 1500
```

**** TOMO 20 MINUTOS ***
 
#### CONCOCT

Primero activemos el ambiente

```{bash eval=FALSE}
conda activate concoct_env
```

Primero los contigs se tienen que partir en pedazos mas pequeños

```{bash split assembly, eval=FALSE}
cut_up_fasta.py htn.fasta -c 10000 -o 0 --merge_last -b SplitAssembly-htn.bed > htn.fasta-split10K.fa
```

Para creas latabla de cobertura se necesita primero indexar el archivo bam

```{bash index bamfile, eval=FALSE}
samtools index htn_sorted.bam
```

```{bash create coverage table, eval=FALSE}
concoct_coverage_table.py SplitAssembly-htn.bed htn_sorted.bam > concoct_coverage_table_htn.tsv
```

Ahora si!! a correr concoct.

Normalmente correriamos 500 iteraciones, pero esta vez solo haremos una.

```{bash run concot, eval=FALSE}
concoct --coverage_file concoct_coverage_table_htn.tsv --composition_file htn.fasta-split10K.fa --clusters 400 --kmer_length 4 --threads 4 --length_threshold 3000 --basename concot --seed 4 --iterations 1
```

Merge subcontig clustering into original contigs

```{bash merge step, eval=FALSE}
merge_cutup_clustering.py concot_clustering_gt3000.csv > merged-htn-gt3000.csv
```

Extract bins as individual fasta.

```{bash make fastafiles, eval=FALSE}
mkdir bins-concot
extract_fasta_bins.py  htn.fasta merged-htn-gt3000.csv --output_path bins-concot
```

#### Vamb

### Calidad y limpieza

#### CheckM

#### mmGenome

### Refinamiento

#### DASTool